{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UZMD5vCsEX1z"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio patchify torch torchvision matplotlib numpy tqdm scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ggiXndfrbn-"
      },
      "outputs": [],
      "source": [
        "import os, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import rasterio\n",
        "from rasterio.plot import reshape_as_image\n",
        "\n",
        "# === Paths ===\n",
        "data_dir = \"../data/\"\n",
        "save_dir = \"../model/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# === Load image & mask (2024 only) ===\n",
        "def load_tif_as_array(filepath):\n",
        "    with rasterio.open(filepath) as src:\n",
        "        img = src.read().astype(np.float32)\n",
        "        img = reshape_as_image(img)\n",
        "    return img\n",
        "\n",
        "def normalize_image(img):\n",
        "    return img / np.max(img)\n",
        "\n",
        "def binarize_mask(mask):\n",
        "    mask = mask[:, :, 0]\n",
        "    if np.max(mask) <= 0.01:\n",
        "        mask = (mask > 0.001).astype(np.uint8)\n",
        "    elif np.max(mask) > 1:\n",
        "        mask = (mask > 128).astype(np.uint8)\n",
        "    else:\n",
        "        mask = (mask > 0.5).astype(np.uint8)\n",
        "    return mask\n",
        "\n",
        "# === Load 2024 data ===\n",
        "img_2024 = normalize_image(load_tif_as_array(\n",
        "    data_dir + \"20241110_053942_45_24f7_3B_AnalyticMS_SR_8b_clip.tif\"\n",
        "))\n",
        "mask_2024 = binarize_mask(load_tif_as_array(\n",
        "    data_dir + \"20241110_053942_45_24f7_3B_AnalyticMS_SR_8b_clip_Hybrid_mask.tif\"\n",
        "))\n",
        "print(\"‚úÖ 2024 image & mask loaded:\", img_2024.shape, mask_2024.shape)\n",
        "\n",
        "# === Patch extraction ===\n",
        "def extract_patches(img, mask, patch_size=256, stride=256):\n",
        "    X, Y = [], []\n",
        "    H, W, _ = img.shape\n",
        "    for i in range(0, H - patch_size, stride):\n",
        "        for j in range(0, W - patch_size, stride):\n",
        "            patch_i = img[i:i+patch_size, j:j+patch_size, :]\n",
        "            patch_m = mask[i:i+patch_size, j:j+patch_size]\n",
        "            if np.sum(patch_m) > 0:  # only patches with some landslide\n",
        "                X.append(patch_i)\n",
        "                Y.append(patch_m)\n",
        "    X, Y = np.array(X), np.array(Y)\n",
        "    Y = np.expand_dims(Y, -1)\n",
        "    return X, Y\n",
        "\n",
        "X, y = extract_patches(img_2024, mask_2024)\n",
        "print(\"‚úÖ Patch dataset:\", X.shape, y.shape)\n",
        "\n",
        "# === Split dataset ===\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Train patches:\", X_train.shape, \"Validation patches:\", X_val.shape)\n",
        "\n",
        "# === Hyperparameters ===\n",
        "EPOCHS = 50\n",
        "LR = 5e-4\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# === Helper blocks ===\n",
        "def residual_block(x, filters):\n",
        "    shortcut = layers.Conv2D(filters, (1,1), padding='same')(x)\n",
        "    x = layers.Conv2D(filters, (3,3), padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(filters, (3,3), padding='same')(x)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, g, filters):\n",
        "    g = layers.UpSampling2D(size=(2,2), interpolation='bilinear')(g)\n",
        "    theta_x = layers.Conv2D(filters, (1,1), padding='same')(x)\n",
        "    phi_g = layers.Conv2D(filters, (1,1), padding='same')(g)\n",
        "    add_xg = layers.Add()([theta_x, phi_g])\n",
        "    act_xg = layers.Activation('relu')(add_xg)\n",
        "    psi = layers.Conv2D(1, (1,1), padding='same', activation='sigmoid')(act_xg)\n",
        "    return layers.Multiply()([x, psi])\n",
        "\n",
        "# === Model 1: U-Net ===\n",
        "def build_unet(input_shape=(256,256,8)):\n",
        "    inputs = layers.Input(input_shape)\n",
        "    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D()(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D()(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D()(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(c4)\n",
        "\n",
        "    u5 = layers.UpSampling2D()(c4)\n",
        "    u5 = layers.Concatenate()([u5, c3])\n",
        "    c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(u5)\n",
        "    c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(c5)\n",
        "\n",
        "    u6 = layers.UpSampling2D()(c5)\n",
        "    u6 = layers.Concatenate()([u6, c2])\n",
        "    c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.UpSampling2D()(c6)\n",
        "    u7 = layers.Concatenate()([u7, c1])\n",
        "    c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(c7)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "# === Model 2: ResU-Net ===\n",
        "def build_resunet(input_shape=(256,256,8)):\n",
        "    inputs = layers.Input(input_shape)\n",
        "    c1 = residual_block(inputs, 32)\n",
        "    p1 = layers.MaxPooling2D()(c1)\n",
        "    c2 = residual_block(p1, 64)\n",
        "    p2 = layers.MaxPooling2D()(c2)\n",
        "    c3 = residual_block(p2, 128)\n",
        "    p3 = layers.MaxPooling2D()(c3)\n",
        "    c4 = residual_block(p3, 256)\n",
        "\n",
        "    u5 = layers.UpSampling2D()(c4)\n",
        "    u5 = layers.Concatenate()([u5, c3])\n",
        "    c5 = residual_block(u5, 128)\n",
        "    u6 = layers.UpSampling2D()(c5)\n",
        "    u6 = layers.Concatenate()([u6, c2])\n",
        "    c6 = residual_block(u6, 64)\n",
        "    u7 = layers.UpSampling2D()(c6)\n",
        "    u7 = layers.Concatenate()([u7, c1])\n",
        "    c7 = residual_block(u7, 32)\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "# === Model 3: Attention U-Net ===\n",
        "def build_att_unet(input_shape=(256,256,8)):\n",
        "    inputs = layers.Input(input_shape)\n",
        "    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "    p1 = layers.MaxPooling2D()(c1)\n",
        "    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(p1)\n",
        "    p2 = layers.MaxPooling2D()(c2)\n",
        "    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(p2)\n",
        "    p3 = layers.MaxPooling2D()(c3)\n",
        "    c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(p3)\n",
        "    g1 = attention_block(c3, c4, 128)\n",
        "    u1 = layers.UpSampling2D()(c4)\n",
        "    u1 = layers.Concatenate()([u1, g1])\n",
        "    c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(u1)\n",
        "    c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(c5)\n",
        "    u2 = layers.UpSampling2D()(c5)\n",
        "    u2 = layers.Concatenate()([u2, c2])\n",
        "    c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(u2)\n",
        "    c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(c6)\n",
        "    u3 = layers.UpSampling2D()(c6)\n",
        "    u3 = layers.Concatenate()([u3, c1])\n",
        "    c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(u3)\n",
        "    c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(c7)\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "# === Model 4: Attention ResU-Net ===\n",
        "def build_att_resunet(input_shape=(256,256,8)):\n",
        "    inputs = layers.Input(input_shape)\n",
        "    c1 = residual_block(inputs, 32)\n",
        "    p1 = layers.MaxPooling2D()(c1)\n",
        "    c2 = residual_block(p1, 64)\n",
        "    p2 = layers.MaxPooling2D()(c2)\n",
        "    c3 = residual_block(p2, 128)\n",
        "    p3 = layers.MaxPooling2D()(c3)\n",
        "    c4 = residual_block(p3, 256)\n",
        "    g1 = attention_block(c3, c4, 128)\n",
        "    u1 = layers.UpSampling2D()(c4)\n",
        "    u1 = layers.Concatenate()([u1, g1])\n",
        "    c5 = residual_block(u1, 128)\n",
        "    u2 = layers.UpSampling2D()(c5)\n",
        "    u2 = layers.Concatenate()([u2, c2])\n",
        "    c6 = residual_block(u2, 64)\n",
        "    u3 = layers.UpSampling2D()(c6)\n",
        "    u3 = layers.Concatenate()([u3, c1])\n",
        "    c7 = residual_block(u3, 32)\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "# === Model 5: ASDMS U-Net ===\n",
        "def build_asdms_unet(input_shape=(256,256,8)):\n",
        "    base = build_unet(input_shape)\n",
        "    return models.Model(base.input, base.output)\n",
        "\n",
        "# === Train-and-save helper ===\n",
        "def train_and_save(model, name):\n",
        "    tf.keras.backend.clear_session()\n",
        "    optimizer_local = optimizers.Adam(learning_rate=LR)\n",
        "    model.compile(optimizer=optimizer_local, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print(f\"\\nüöÄ Training {name} on 2024 data ... (50 epochs)\")\n",
        "    hist = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=8,\n",
        "        verbose=1\n",
        "    )\n",
        "    model.save(os.path.join(save_dir, f\"{name}_2022.keras\"))\n",
        "    print(f\"‚úÖ Saved {name}_2022.keras\\n\")\n",
        "    return hist\n",
        "\n",
        "# === Build and train all models ===\n",
        "models_to_train = {\n",
        "    \"unet\": build_unet(),\n",
        "    \"resunet\": build_resunet(),\n",
        "    \"att_unet\": build_att_unet(),\n",
        "    \"att_resunet\": build_att_resunet(),\n",
        "    \"asdms_unet\": build_asdms_unet()\n",
        "}\n",
        "\n",
        "histories_2024 = {}\n",
        "for name, model in models_to_train.items():\n",
        "    histories_2024[name] = train_and_save(model, name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9dqdMrnj-q8"
      },
      "outputs": [],
      "source": [
        "import os, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import rasterio\n",
        "from rasterio.plot import reshape_as_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Paths ===\n",
        "data_dir = \"../data/\"\n",
        "model_dir = \"/model/\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# === Load 2022 image ===\n",
        "def load_tif_as_array(filepath):\n",
        "    with rasterio.open(filepath) as src:\n",
        "        img = src.read().astype(np.float32)\n",
        "        img = reshape_as_image(img)\n",
        "    return img\n",
        "\n",
        "def normalize_image(img):\n",
        "    return img / np.max(img)\n",
        "\n",
        "img_2022 = normalize_image(load_tif_as_array(\n",
        "    data_dir + \"20220503_050008_52_2474_3B_AnalyticMS_8b_clip.tif\"\n",
        "))\n",
        "print(\"‚úÖ Loaded 2024 image:\", img_2022.shape)\n",
        "\n",
        "# === Patch-based prediction ===\n",
        "def predict_large_image(model, image, patch_size=256):\n",
        "    H, W, C = image.shape\n",
        "    out_mask = np.zeros((H, W), dtype=np.uint8)\n",
        "    n_rows = math.ceil(H / patch_size)\n",
        "    n_cols = math.ceil(W / patch_size)\n",
        "\n",
        "    for i in range(n_rows):\n",
        "        for j in range(n_cols):\n",
        "            y0, y1 = i * patch_size, min((i + 1) * patch_size, H)\n",
        "            x0, x1 = j * patch_size, min((j + 1) * patch_size, W)\n",
        "            patch = image[y0:y1, x0:x1, :]\n",
        "            pad_h, pad_w = patch_size - patch.shape[0], patch_size - patch.shape[1]\n",
        "            patch_padded = np.pad(patch, ((0, pad_h), (0, pad_w), (0, 0)), mode='reflect')\n",
        "            pred = model.predict(np.expand_dims(patch_padded, axis=0), verbose=0)\n",
        "            pred_mask = (pred[0, :, :, 0] > 0.5).astype(np.uint8)\n",
        "            out_mask[y0:y1, x0:x1] = pred_mask[:patch.shape[0], :patch.shape[1]]\n",
        "    return out_mask\n",
        "\n",
        "# === Visualization + Save (No Ground Truth) ===\n",
        "def visualize_and_save_prediction(image, pred_mask, model_name, save_dir):\n",
        "    rgb = (image[:, :, :3] - np.min(image[:, :, :3])) / (np.max(image[:, :, :3]) - np.min(image[:, :, :3]))\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Satellite\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(rgb)\n",
        "    plt.title(\"Satellite Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Predicted mask\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(pred_mask, cmap='gray')\n",
        "    plt.title(f\"Predicted Mask ({model_name})\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(save_dir, f\"{model_name}_2022_prediction.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Saved {model_name} prediction ‚Üí {save_path}\")\n",
        "\n",
        "# === Model list ===\n",
        "model_names = [\n",
        "    \"unet_2022.keras\",\n",
        "    \"resunet_2022.keras\",\n",
        "    \"att_unet_2022.keras\",\n",
        "    \"att_resunet_2022.keras\",\n",
        "    \"asdms_unet_2022.keras\"\n",
        "]\n",
        "\n",
        "# === Test & Save All ===\n",
        "for mname in model_names:\n",
        "    path = os.path.join(model_dir, mname)\n",
        "    if os.path.exists(path):\n",
        "        print(f\"\\nüöÄ Testing {mname} ...\")\n",
        "        model = tf.keras.models.load_model(path, compile=False)\n",
        "        pred_mask = predict_large_image(model, img_2022)\n",
        "        visualize_and_save_prediction(img_2022, pred_mask, mname.replace(\"_2022.keras\", \"\"), model_dir)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Model not found: {path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIrKOWWDorae"
      },
      "outputs": [],
      "source": [
        "import os, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import rasterio\n",
        "from rasterio.plot import reshape_as_image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# === Paths ===\n",
        "data_dir = \"../data/\"\n",
        "model_dir = \"../model/\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# === Load 2022 image + mask ===\n",
        "def load_tif_as_array(filepath):\n",
        "    with rasterio.open(filepath) as src:\n",
        "        img = src.read().astype(np.float32)\n",
        "        img = reshape_as_image(img)\n",
        "    return img\n",
        "\n",
        "def normalize_image(img):\n",
        "    return img / np.max(img)\n",
        "\n",
        "def binarize_mask(mask):\n",
        "    mask = mask[:, :, 0]\n",
        "    if np.max(mask) <= 0.01:\n",
        "        mask = (mask > 0.001).astype(np.uint8)\n",
        "    elif np.max(mask) > 1:\n",
        "        mask = (mask > 128).astype(np.uint8)\n",
        "    else:\n",
        "        mask = (mask > 0.5).astype(np.uint8)\n",
        "    return mask\n",
        "\n",
        "img_2022 = normalize_image(load_tif_as_array(\n",
        "    data_dir + \"20220503_050008_52_2474_3B_AnalyticMS_8b_clip.tif\"\n",
        "))\n",
        "mask_2022 = binarize_mask(load_tif_as_array(\n",
        "    data_dir + \"landslide_mask_20220503_final.tif\"\n",
        "))\n",
        "print(\"‚úÖ Loaded 2022 data:\", img_2022.shape, mask_2022.shape)\n",
        "\n",
        "# === Patch-based prediction ===\n",
        "def predict_large_image(model, image, patch_size=256):\n",
        "    H, W, C = image.shape\n",
        "    out_mask = np.zeros((H, W), dtype=np.uint8)\n",
        "    n_rows = math.ceil(H / patch_size)\n",
        "    n_cols = math.ceil(W / patch_size)\n",
        "    for i in range(n_rows):\n",
        "        for j in range(n_cols):\n",
        "            y0, y1 = i * patch_size, min((i + 1) * patch_size, H)\n",
        "            x0, x1 = j * patch_size, min((j + 1) * patch_size, W)\n",
        "            patch = image[y0:y1, x0:x1, :]\n",
        "            pad_h, pad_w = patch_size - patch.shape[0], patch_size - patch.shape[1]\n",
        "            patch_padded = np.pad(patch, ((0, pad_h), (0, pad_w), (0, 0)), mode='reflect')\n",
        "            pred = model.predict(np.expand_dims(patch_padded, axis=0), verbose=0)\n",
        "            pred_mask = (pred[0, :, :, 0] > 0.5).astype(np.uint8)\n",
        "            out_mask[y0:y1, x0:x1] = pred_mask[:patch.shape[0], :patch.shape[1]]\n",
        "    return out_mask\n",
        "\n",
        "# === Compute metrics ===\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    intersection = np.sum(np.logical_and(y_true, y_pred))\n",
        "    union = np.sum(np.logical_or(y_true, y_pred))\n",
        "    iou = intersection / (union + 1e-8)\n",
        "    dice = (2 * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-8)\n",
        "    report = classification_report(y_true.flatten(), y_pred.flatten(), output_dict=True, zero_division=0)\n",
        "    return {\n",
        "        \"Accuracy\": report[\"accuracy\"],\n",
        "        \"Precision\": report[\"1\"][\"precision\"],\n",
        "        \"Recall\": report[\"1\"][\"recall\"],\n",
        "        \"F1-Score\": report[\"1\"][\"f1-score\"],\n",
        "        \"IoU\": iou,\n",
        "        \"Dice\": dice\n",
        "    }\n",
        "\n",
        "# === Visualization ===\n",
        "def plot_confusion_matrix(y_true, y_pred, model_name, save_dir):\n",
        "    cm = confusion_matrix(y_true.flatten(), y_pred.flatten())\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    path = os.path.join(save_dir, f\"{model_name}_2022_confusion.png\")\n",
        "    plt.savefig(path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Saved confusion matrix: {path}\")\n",
        "\n",
        "def plot_radar(metrics_dict, model_name, save_dir):\n",
        "    categories = list(metrics_dict.keys())\n",
        "    values = list(metrics_dict.values())\n",
        "    values += values[:1]  # close the loop\n",
        "    angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=model_name)\n",
        "    ax.fill(angles, values, alpha=0.25)\n",
        "    ax.set_yticks(np.linspace(0,1,5))\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(categories)\n",
        "    plt.title(f\"Performance Radar - {model_name}\")\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(save_dir, f\"{model_name}_2022_radar.png\")\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Saved radar plot: {save_path}\")\n",
        "\n",
        "# === Test all models ===\n",
        "model_names = [\n",
        "    \"unet_2022.keras\",\n",
        "    \"resunet_2022.keras\",\n",
        "    \"att_unet_2022.keras\",\n",
        "    \"att_resunet_2022.keras\",\n",
        "    \"asdms_unet_2022.keras\"\n",
        "]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for mname in model_names:\n",
        "    model_path = os.path.join(model_dir, mname)\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"\\nüöÄ Testing {mname} ...\")\n",
        "        model = tf.keras.models.load_model(model_path, compile=False)\n",
        "        pred_mask = predict_large_image(model, img_2022)\n",
        "        true_mask = mask_2022[:pred_mask.shape[0], :pred_mask.shape[1]]\n",
        "\n",
        "        # Metrics\n",
        "        metrics = compute_metrics(true_mask, pred_mask)\n",
        "        results[mname.replace(\"_2022.keras\", \"\")] = metrics\n",
        "\n",
        "        # Plots\n",
        "        plot_confusion_matrix(true_mask, pred_mask, mname.replace(\"_2022.keras\", \"\"), model_dir)\n",
        "        plot_radar(metrics, mname.replace(\"_2022.keras\", \"\"), model_dir)\n",
        "\n",
        "# === Save metrics summary ===\n",
        "df = pd.DataFrame(results).T.round(4)\n",
        "csv_path = os.path.join(model_dir, \"metrics_summary_2022.csv\")\n",
        "df.to_csv(csv_path)\n",
        "print(f\"\\n‚úÖ Metrics saved to CSV: {csv_path}\")\n",
        "\n",
        "# === Bar plot comparison ===\n",
        "plt.figure(figsize=(10,6))\n",
        "df.plot(kind='bar', figsize=(10,6))\n",
        "plt.title(\"Model Performance Comparison (2022 Data)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0,1)\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "bar_save_path = os.path.join(model_dir, \"barplot_metrics_2022.png\")\n",
        "plt.savefig(bar_save_path, dpi=300)\n",
        "plt.close()\n",
        "print(f\"‚úÖ Saved bar plot: {bar_save_path}\")\n",
        "\n",
        "print(\"\\nüìä Final Results (All 5 Models on 2022 Data):\")\n",
        "display(df)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
